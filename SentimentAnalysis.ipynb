{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2S8I2ny-ovS"
      },
      "source": [
        "# NLE Assignment: Sentiment Classification\n",
        "\n",
        "In this assignment, you will be investigating NLP methods for distinguishing positive and negative reviews written about movies.\n",
        "\n",
        "For assessment, you are expected to complete and submit this notebook file.  When answers require code, you may import and use library functions (unless explicitly told otherwise).  All of your own code should be included in the notebook rather than imported from elsewhere.  Written answers should also be included in the notebook.  You should insert as many extra cells as you want and change the type between code and markdown as appropriate.\n",
        "\n",
        "In order to avoid misconduct, you should not talk about the assignment questions with your peers.  If you are not sure what a question is asking you to do or have any other questions, please ask me or one of the Teaching Assistants.\n",
        "\n",
        "Marking guidelines are provided as a separate document.\n",
        "\n",
        "The first few cells contain code to set-up the assignment and bring in some data.   In order to provide unique datasets for analysis by different students, you must enter your candidate number in the following cell.  Otherwise do not change the code in these cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "1gXQAZas-l9c"
      },
      "outputs": [],
      "source": [
        "candidateno=233814 #this MUST be updated to your candidate number so that you get a unique data sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "nk8JTP88A8vs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e80bc6c-046b-4293-8254-cf031af4d0e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#do not change the code in this cell\n",
        "#preliminary imports\n",
        "\n",
        "#set up nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('movie_reviews')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "#for setting up training and testing data\n",
        "import random\n",
        "\n",
        "#useful other tools\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from itertools import zip_longest\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.classify.api import ClassifierI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "BHBkzAccCVaZ"
      },
      "outputs": [],
      "source": [
        "#do not change the code in this cell\n",
        "def split_data(data, ratio=0.7): # when the second argument is not given, it defaults to 0.7\n",
        "    \"\"\"\n",
        "    Given corpus generator and ratio:\n",
        "     - partitions the corpus into training data and test data, where the proportion in train is ratio,\n",
        "\n",
        "    :param data: A corpus generator.\n",
        "    :param ratio: The proportion of training documents (default 0.7)\n",
        "    :return: a pair (tuple) of lists where the first element of the \n",
        "            pair is a list of the training data and the second is a list of the test data.\n",
        "    \"\"\"\n",
        "    \n",
        "    data = list(data)  \n",
        "    n = len(data)  \n",
        "    train_indices = random.sample(range(n), int(n * ratio))          \n",
        "    test_indices = list(set(range(n)) - set(train_indices))    \n",
        "    train = [data[i] for i in train_indices]           \n",
        "    test = [data[i] for i in test_indices]             \n",
        "    return (train, test)                       \n",
        " \n",
        "\n",
        "def get_train_test_data():\n",
        "    \n",
        "    #get ids of positive and negative movie reviews\n",
        "    pos_review_ids=movie_reviews.fileids('pos')\n",
        "    neg_review_ids=movie_reviews.fileids('neg')\n",
        "   \n",
        "    #split positive and negative data into training and testing sets\n",
        "    pos_train_ids, pos_test_ids = split_data(pos_review_ids)\n",
        "    neg_train_ids, neg_test_ids = split_data(neg_review_ids)\n",
        "    #add labels to the data and concatenate\n",
        "    training = [(movie_reviews.words(f),'pos') for f in pos_train_ids]+[(movie_reviews.words(f),'neg') for f in neg_train_ids]\n",
        "    testing = [(movie_reviews.words(f),'pos') for f in pos_test_ids]+[(movie_reviews.words(f),'neg') for f in neg_test_ids]\n",
        "   \n",
        "    return training, testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N3LWwBYICPP"
      },
      "source": [
        "When you have run the cell below, your unique training and testing samples will be stored in `training_data` and `testing_data`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "HJLegkdPFUJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c5c56f-abc3-4af1-b315-a89aa156f284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The amount of training data is 1400\n",
            "The amount of testing data is 600\n",
            "The representation of a single data item is below\n",
            "(['\"', 'footloose', '\"', 'has', 'only', 'one', 'goal', ...], 'pos')\n"
          ]
        }
      ],
      "source": [
        "#do not change the code in this cell\n",
        "random.seed(candidateno)\n",
        "training_data,testing_data=get_train_test_data()\n",
        "print(\"The amount of training data is {}\".format(len(training_data)))\n",
        "print(\"The amount of testing data is {}\".format(len(testing_data)))\n",
        "print(\"The representation of a single data item is below\")\n",
        "print(training_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE3bKQbB50Rq"
      },
      "source": [
        "1)  \n",
        "a) **Generate** a list of 10 content words which are representative of the positive reviews in your training data.\n",
        "\n",
        "b) **Generate** a list of 10 content words which are representative of the negative reviews in your training data.\n",
        "\n",
        "c) **Explain** what you have done and why\n",
        "\n",
        "[20\\%]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# separates the data into positive and negative review lists\n",
        "def split_pos_neg(training_data):\n",
        "  pos_data = []\n",
        "  neg_data = []\n",
        "  for review in training_data:\n",
        "    words = review[0]\n",
        "    if review[1] == 'pos':\n",
        "      tup = (words,'pos')\n",
        "      pos_data.append(tup)\n",
        "    if review[1] == 'neg':\n",
        "      tup = (words,'neg')\n",
        "      neg_data.append(tup)\n",
        "  return pos_data, neg_data \n",
        "  \n",
        "pos_data,neg_data = split_pos_neg(training_data)"
      ],
      "metadata": {
        "id": "5pkxK-IxFmGV"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = stopwords.words('english')\n",
        "import collections\n",
        "from collections import Counter\n",
        "\n",
        "#normalises the positive data by removing non alphabetic characters, removing stopwords and stemming the words\n",
        "def normalise_data(data):\n",
        "  normalised_data = []\n",
        "  for x in data:\n",
        "    words = x[0]\n",
        "    words = [word for word in words if word.isalpha()]\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    words = [stemmer.stem(word) for word in words]\n",
        "    tup = (words, x[1])\n",
        "    normalised_data.append(tup)\n",
        "  return normalised_data\n",
        "\n",
        "normalisedpos_data = normalise_data(pos_data)\n",
        "normalisedneg_data = normalise_data(neg_data)\n",
        "\n",
        "# produces a frequency distribution for the words in each normalised review\n",
        "def produce_dict(data):\n",
        "  wordfreqdict = {}\n",
        "  for review in data:\n",
        "    words = review[0]\n",
        "    for word in words:\n",
        "      if word not in wordfreqdict.keys():\n",
        "          wordfreqdict[word] = 1\n",
        "      else:\n",
        "          wordfreqdict[word] += 1\n",
        "  return wordfreqdict\n",
        "\n",
        "poswordfreq = produce_dict(normalisedpos_data)\n",
        "negwordfreq = produce_dict(normalisedneg_data)\n"
      ],
      "metadata": {
        "id": "qPGfZCPG6zpE"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This function gets the top words that occur more in positive or negative data\n",
        "def most_frequent_words(dict1,dict2,k):\n",
        "  dict1copy = dict(dict1)\n",
        "  for key in dict1:\n",
        "    if key in dict2:\n",
        "      dict1copy[key] = dict1[key]- dict2[key]\n",
        "  return dict(Counter(dict1copy).most_common(k))       \n",
        "\n",
        "generated_pos_list = most_frequent_words(poswordfreq,negwordfreq,10)\n",
        "generated_neg_list = most_frequent_words(negwordfreq,poswordfreq,10)\n",
        "\n",
        "print(\"positive word list: {}\".format(generated_pos_list))\n",
        "print(\"negative word list: {}\".format(generated_neg_list))\n"
      ],
      "metadata": {
        "id": "8x6buElu6uV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90e50f18-78df-4af3-e213-89e2c76e3a47"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive word list: {'film': 781, 'life': 396, 'also': 319, 'great': 274, 'well': 269, 'perform': 250, 'love': 242, 'charact': 235, 'mani': 234, 'war': 230}\n",
            "negative word list: {'bad': 471, 'movi': 326, 'plot': 218, 'look': 201, 'even': 199, 'bore': 165, 'worst': 147, 'wast': 146, 'script': 144, 'suppos': 144}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I separated the data into positive and negative data sets. I then normalised the data by filtering out stopwords and non alphabetic characters and stemming the words. I produced frequency distributions for the positive and negative reviews sets and then defined a most_common_words function to get the 10 words that occur more in one data set than the other which are the most useful words"
      ],
      "metadata": {
        "id": "6NSguXx7YtJH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TApOQE6vND20"
      },
      "source": [
        "2) \n",
        "a) **Use** the lists generated in Q1 to build a **word list classifier** which will classify reviews as being positive or negative.\n",
        "\n",
        "b) **Explain** what you have done.\n",
        "\n",
        "[12.5\\%]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "BThDMrcmODJy"
      },
      "outputs": [],
      "source": [
        "from nltk.classify.api import ClassifierI\n",
        "import random\n",
        "\n",
        "class SimpleClassifier(ClassifierI): \n",
        "\n",
        "    def __init__(self, pos, neg): \n",
        "        self._pos = pos \n",
        "        self._neg = neg \n",
        "\n",
        "    def classify(self, words): \n",
        "        score = 0\n",
        "        for word in words:\n",
        "          word = stemmer.stem(word) \n",
        "          if word in self._pos:\n",
        "            score = score + 1\n",
        "          if word in self._neg:\n",
        "            score = score - 1\n",
        "        \n",
        "        if score < 0:\n",
        "          return 'neg'\n",
        "        if score > 0:\n",
        "          return 'pos'\n",
        "        else: random.choice(['pos', 'neg'])\n",
        "\n",
        "    ##we don't actually need to define the classify_many method as it is provided in ClassifierI\n",
        "    #def classify_many(self, docs): \n",
        "    #    return [self.classify(doc) for doc in docs] \n",
        "\n",
        "    def labels(self): \n",
        "        return (\"pos\", \"neg\")\n",
        "\n",
        "classifier = SimpleClassifier(generated_pos_list, generated_neg_list)      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6xxvcyr50Rv"
      },
      "source": [
        "I looped through the words that are input to the classifier and checked if that word was in the negative or positive word list. If it was in the positive list the score variable would be incremented and if negative score would be decremented. If score was ultimately above 0 the review would be labelled 'pos', if below it would be 'neg' and if it was 0 then a label would be randomly chosen between pos and neg."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL1iL9jg50Rv"
      },
      "source": [
        "3)\n",
        "a) **Calculate** the accuracy, precision, recall and F1 score of your classifier.\n",
        "\n",
        "b) Is it reasonable to evaluate the classifier in terms of its accuracy?  **Explain** your answer and give a counter-example (a scenario where it would / would not be reasonable to evaluate the classifier in terms of its accuracy).\n",
        "\n",
        "[20\\%]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "r1PrZnTe50Rw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c33a8a7a-d283-4e06-c0d4-764d4ffe9f99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.615\n",
            "Precision: 0.603448275862069\n",
            "Recall: 0.8166666666666667\n",
            "f1 score: 0.6940509915014165\n"
          ]
        }
      ],
      "source": [
        "from nltk.metrics.scores import precision, recall, f_measure\n",
        "accuracy = nltk.classify.accuracy(classifier, testing_data)\n",
        "print(\"accuracy: {}\".format(accuracy))\n",
        "\n",
        "reference = collections.defaultdict(set)\n",
        "test = collections.defaultdict(set)\n",
        "\n",
        "# gets the precision recall and f1 score\n",
        "for i, (feats, label) in enumerate(testing_data):\n",
        "    reference[label].add(i)\n",
        "    observed = classifier.classify(feats)\n",
        "    test[observed].add(i)\n",
        "print('Precision:',precision(reference['pos'], test['pos']))\n",
        "print('Recall:',recall(reference['pos'], test['pos']))\n",
        "print('f1 score:',f_measure(reference['pos'], test['pos']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gHYwj0i50Ry"
      },
      "source": [
        "It is reasonable to evaluate this classifier by accuracy because the training data is well balanced; the number of positive and negative reviews used to train the classifier are the same. It would not be reasonable for something like spam email classification because a classifier could predict all emails to not be spam and get a high accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIS9UpmJNEAp"
      },
      "source": [
        "4) \n",
        "a)  **Construct** a Naive Bayes classifier (e.g., from NLTK).\n",
        "\n",
        "b)  **Compare** the performance of your word list classifier with the Naive Bayes classifier.  **Discuss** your results. \n",
        "\n",
        "[12.5\\%]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "hG4DSeqD50Rz"
      },
      "outputs": [],
      "source": [
        "from nltk.classify import NaiveBayesClassifier\n",
        "\n",
        "# constructs and train a Naive Bayes classifier\n",
        "def word_feats(words):\n",
        "    return dict([(word, True) for word in words if word not in stop_words])\n",
        "pos_feats = [(word_feats(f[0]), 'pos') for f in normalisedpos_data ]\n",
        "neg_feats = [(word_feats(f[0]), 'neg') for f in normalisedneg_data ]\n",
        "testing_feats = [(word_feats(f[0]), f[1]) for f in testing_data]\n",
        "trainfeats = pos_feats + neg_feats\n",
        "nbclassifier = NaiveBayesClassifier.train(trainfeats)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "56_oD8ET50Rz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45034009-121d-4088-a8d5-a0cb2bfd668b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "naive bayes classifier accuracy : 0.6966666666666667\n"
          ]
        }
      ],
      "source": [
        "print(\"naive bayes classifier accuracy :\",nltk.classify.accuracy(nbclassifier, testing_feats))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfuYer9U50Rz"
      },
      "source": [
        "The accuracy of the naive bayes classifier is higher than the accuracy of the word list and as the data is balances accuracy is a good measure of the performance of a classifier on this data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGDXaVDqOSfY"
      },
      "source": [
        "5) \n",
        "a) Design and **carry out an experiment** into the impact of the **length of the wordlists** on the wordlist classifier.  Make sure you **describe** design decisions in your experiment, include a **graph** of your results and **discuss** your conclusions. \n",
        "\n",
        "b) Would you **recommend** a wordlist classifier or a Naive Bayes classifier for future work in this area?  **Justify** your answer.\n",
        "\n",
        "[25\\%]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PVBBPhh50R0"
      },
      "source": [
        "I used 10 list lengths in my experiment from 5 to 50 in increments of 5. Accuracy is the only measure used because the classes are balanced. From my results i have found that my graph has bimodial distribution and the two modes are 10 and 30 words. Less than 10 words is suboptimal and so is more than 30 words as the accuracy goes down."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "9tBhqZtw50R1"
      },
      "outputs": [],
      "source": [
        "posi_data,nega_data = split_pos_neg(training_data)\n",
        "train_train_pos = posi_data[:490] \n",
        "train_test = posi_data[-210:] + nega_data[-210:]\n",
        "train_train_neg = nega_data[:490]\n",
        "train_train_pos_n = normalise_data(train_train_pos)\n",
        "train_train_neg_n = normalise_data(train_train_neg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "J1ozKYMa50R1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b82b71b8-f492-4f26-8ee7-992ea35eb8ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5785714285714286\n",
            "0.6309523809523809\n",
            "0.6214285714285714\n",
            "0.6142857142857143\n",
            "0.6142857142857143\n",
            "0.6309523809523809\n",
            "0.6166666666666667\n",
            "0.6023809523809524\n",
            "0.5904761904761905\n",
            "0.6\n"
          ]
        }
      ],
      "source": [
        "pos_dict = produce_dict(train_train_pos_n)\n",
        "neg_dict = produce_dict(train_train_neg_n)\n",
        "\n",
        "\n",
        "pos_train_list1 = most_frequent_words(pos_dict,neg_dict,5)\n",
        "pos_train_list2 = most_frequent_words(pos_dict,neg_dict,10)\n",
        "pos_train_list3 = most_frequent_words(pos_dict,neg_dict,15)\n",
        "pos_train_list4 = most_frequent_words(pos_dict,neg_dict,20)\n",
        "pos_train_list5 = most_frequent_words(pos_dict,neg_dict,25)\n",
        "pos_train_list6 = most_frequent_words(pos_dict,neg_dict,30)\n",
        "pos_train_list7 = most_frequent_words(pos_dict,neg_dict,35)\n",
        "pos_train_list8 = most_frequent_words(pos_dict,neg_dict,40)\n",
        "pos_train_list9 = most_frequent_words(pos_dict,neg_dict,45)\n",
        "pos_train_list10 = most_frequent_words(pos_dict,neg_dict,50)\n",
        "\n",
        "neg_train_list1 = most_frequent_words(neg_dict,pos_dict,5)\n",
        "neg_train_list2 = most_frequent_words(neg_dict,pos_dict,10)\n",
        "neg_train_list3 = most_frequent_words(neg_dict,pos_dict,15)\n",
        "neg_train_list4 = most_frequent_words(neg_dict,pos_dict,20)\n",
        "neg_train_list5 = most_frequent_words(neg_dict,pos_dict,25)\n",
        "neg_train_list6 = most_frequent_words(neg_dict,pos_dict,30)\n",
        "neg_train_list7 = most_frequent_words(neg_dict,pos_dict,35)\n",
        "neg_train_list8 = most_frequent_words(neg_dict,pos_dict,40)\n",
        "neg_train_list9 = most_frequent_words(neg_dict,pos_dict,45)\n",
        "neg_train_list10 = most_frequent_words(neg_dict,pos_dict,50)\n",
        "\n",
        "wlclassifier1 = SimpleClassifier(pos_train_list1,neg_train_list1)\n",
        "wlclassifier2 = SimpleClassifier(pos_train_list2,neg_train_list2)\n",
        "wlclassifier3 = SimpleClassifier(pos_train_list3,neg_train_list3)\n",
        "wlclassifier4 = SimpleClassifier(pos_train_list4,neg_train_list4)\n",
        "wlclassifier5 = SimpleClassifier(pos_train_list5,neg_train_list5)\n",
        "wlclassifier6 = SimpleClassifier(pos_train_list6,neg_train_list6)\n",
        "wlclassifier7 = SimpleClassifier(pos_train_list7,neg_train_list7)\n",
        "wlclassifier8 = SimpleClassifier(pos_train_list8,neg_train_list8)\n",
        "wlclassifier9 = SimpleClassifier(pos_train_list9,neg_train_list9)\n",
        "wlclassifier10 = SimpleClassifier(pos_train_list10,neg_train_list10)\n",
        "\n",
        "wlaccuracy1 = nltk.classify.accuracy(wlclassifier1, train_test)\n",
        "wlaccuracy2 = nltk.classify.accuracy(wlclassifier2, train_test)\n",
        "wlaccuracy3 = nltk.classify.accuracy(wlclassifier3, train_test)\n",
        "wlaccuracy4 = nltk.classify.accuracy(wlclassifier4, train_test)\n",
        "wlaccuracy5 = nltk.classify.accuracy(wlclassifier5, train_test)\n",
        "wlaccuracy6 = nltk.classify.accuracy(wlclassifier6, train_test)\n",
        "wlaccuracy7 = nltk.classify.accuracy(wlclassifier7, train_test)\n",
        "wlaccuracy8 = nltk.classify.accuracy(wlclassifier8, train_test)\n",
        "wlaccuracy9 = nltk.classify.accuracy(wlclassifier9, train_test)\n",
        "wlaccuracy10 = nltk.classify.accuracy(wlclassifier10, train_test)\n",
        "\n",
        "print(wlaccuracy1)\n",
        "print(wlaccuracy2)\n",
        "print(wlaccuracy3)\n",
        "print(wlaccuracy4)\n",
        "print(wlaccuracy5)\n",
        "print(wlaccuracy6)\n",
        "print(wlaccuracy7)\n",
        "print(wlaccuracy8)\n",
        "print(wlaccuracy9)\n",
        "print(wlaccuracy10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "vzN_HIuC50R1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "bbcca181-65db-4b26-85ae-5ad0d25e6650"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x = [5,10,15,20,25,30,35,40,45,50]\n",
        "y = [0.579,0.631,0.621,0.614,0.614,0.631,0.617,0.602,0.590,0.6]\n",
        "\n",
        "plt.plot(x,y)\n",
        "plt.title(\"impact of word list length\")\n",
        "plt.xlabel(\"word list length\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYZVd15L50R2"
      },
      "source": [
        "I would recommend the naive bayes classifier over the word list classifier because even at the optimal length of 10 words the naive bayes outperforms the word list classifier on accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "34rdlS_iPov6",
        "outputId": "3d8480a6-0e33-4b75-d67f-3622e1bf1c6c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-85c2af388216>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mquestion_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m437\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'NLassignment2022.ipynb'"
          ]
        }
      ],
      "source": [
        "##This code will word count all of the markdown cells in the notebook saved at filepath\n",
        "##Running it before providing any answers shows that the questions have a word count of 437\n",
        "\n",
        "import io\n",
        "from nbformat import current\n",
        "\n",
        "#filepath=\"/content/drive/My Drive/NLE Notebooks/assessment/assignment1.ipynb\"\n",
        "filepath=\"NLassignment2022.ipynb\"\n",
        "question_count=437\n",
        "\n",
        "with io.open(filepath, 'r', encoding='utf-8') as f:\n",
        "    nb = current.read(f, 'json')\n",
        "\n",
        "word_count = 0\n",
        "for cell in nb.worksheets[0].cells:\n",
        "    if cell.cell_type == \"markdown\":\n",
        "        word_count += len(cell['source'].replace('#', '').lstrip().split(' '))\n",
        "print(\"Submission length is {}\".format(word_count-question_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtqCcG6wPsmf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}